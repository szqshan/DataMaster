# 📚 DataMaster MCP 用户使用手册

> **完整的数据分析工具使用指南** - 从入门到精通

---

## 🎯 快速开始

### 安装依赖

```bash
pip install -r requirements.txt
```

### 启动服务

```bash
python main.py
```

---

## 📊 核心功能概览

### 🔗 数据源连接
- **Excel/CSV文件导入** - 支持多种格式和编码
- **数据库连接** - MySQL、PostgreSQL、MongoDB、SQLite
- **API数据获取** - RESTful API连接和数据提取

### 🔍 数据查询分析
- **SQL查询执行** - 本地和外部数据库查询
- **数据统计分析** - 基础统计、相关性、异常值检测
- **数据质量检查** - 缺失值、重复值分析

### 🛠️ 数据处理
- **数据清洗** - 去重、填充缺失值
- **数据转换** - 类型转换、格式化
- **数据聚合** - 分组统计、汇总

### 📤 数据导出
- **多格式导出** - Excel、CSV、JSON
- **查询结果导出** - 支持SQL查询结果导出

---

## 🔗 数据库连接功能

### 支持的数据库类型

- **MySQL** - 关系型数据库
- **PostgreSQL** - 关系型数据库  
- **MongoDB** - 文档型数据库
- **SQLite** - 轻量级关系型数据库

### 连接方式

#### 方式一：配置文件连接（推荐）

1. **配置数据库信息**

编辑 `config/database_config.json`：

```json
{
  "databases": {
    "my_mysql": {
      "type": "mysql",
      "host": "localhost",
      "port": 3306,
      "database": "my_database",
      "username": "root",
      "password": "${MYSQL_PASSWORD}",
      "charset": "utf8mb4",
      "description": "我的MySQL数据库",
      "enabled": true
    },
    "my_postgres": {
      "type": "postgresql",
      "host": "localhost",
      "port": 5432,
      "database": "my_database",
      "username": "postgres",
      "password": "${POSTGRES_PASSWORD}",
      "schema": "public",
      "description": "我的PostgreSQL数据库",
      "enabled": true
    }
  }
}
```

2. **设置环境变量**

编辑 `.env` 文件：

```env
# 数据库密码
MYSQL_PASSWORD=your_mysql_password
POSTGRES_PASSWORD=your_postgres_password
MONGO_PASSWORD=your_mongo_password
```

#### 方式二：直接连接

```python
# MySQL连接
connect_data_source(
    source_type="mysql",
    config={
        "host": "localhost",
        "port": 3306,
        "database": "test_db",
        "username": "root",  # 支持 user 或 username
        "password": "password"
    }
)

# PostgreSQL连接
connect_data_source(
    source_type="postgresql",
    config={
        "host": "localhost",
        "port": 5432,
        "database": "test_db",
        "username": "postgres",
        "password": "password"
    }
)
```

### 数据库管理

```python
# 列出所有配置
manage_database_config(action="list")

# 测试连接
manage_database_config(
    action="test",
    config={"database_name": "my_mysql"}
)

# 添加新配置
manage_database_config(
    action="add",
    config={
        "database_name": "new_db",
        "database_config": {
            "type": "mysql",
            "host": "192.168.1.100",
            "port": 3306,
            "database": "test_db",
            "username": "user",
            "password": "pass"
        }
    }
)
```

---

## 🌐 API连接器功能

### 支持的认证方式

- **API Key** - Query参数或Header方式
- **Bearer Token** - OAuth 2.0认证
- **Basic认证** - 用户名/密码
- **自定义Header** - 灵活的认证头
- **无认证** - 公开API

### API配置管理

```python
# 添加API配置
manage_api_config(
    action="add",
    api_name="weather_api",
    config_data={
        "base_url": "https://api.openweathermap.org/data/2.5",
        "auth_type": "api_key",
        "auth_config": {
            "api_key": "${WEATHER_API_KEY}",
            "key_param": "appid",
            "key_location": "query"
        },
        "endpoints": {
            "current_weather": {
                "path": "/weather",
                "method": "GET",
                "description": "获取当前天气"
            }
        }
    }
)

# 列出API配置
manage_api_config(action="list")

# 获取API端点
manage_api_config(action="get_endpoints", api_name="weather_api")
```

### API数据获取与存储

**重要说明：** 所有API数据现在都会自动存储到数据库中，无需手动管理存储流程。

```python
# 基本API调用（自动存储到数据库）
fetch_api_data(
    api_name="weather_api",
    endpoint_name="current_weather",
    params={"q": "Beijing", "units": "metric"}
)

# 带数据转换的调用（自动存储到数据库）
fetch_api_data(
    api_name="rest_api",
    endpoint_name="users",
    transform_config={
        "field_mapping": {
            "user_id": "id",
            "user_name": "name"
        },
        "include_fields": ["id", "name", "email"]
    }
)

# 预览API数据
api_data_preview(
    api_name="weather_api",
    endpoint_name="current_weather",
    params={"q": "Shanghai"},
    max_rows=5
)

# 创建存储会话（可选，用于组织数据）
create_api_storage_session(
    session_name="weather_data",
    api_name="weather_api",
    endpoint_name="current_weather",
    description="天气数据收集"
)
```

**数据流程简化：**
- ✅ **自动存储**：所有API数据自动存储到数据库
- ✅ **会话管理**：通过session_id组织和管理数据
- ✅ **数据查询**：直接从数据库查询API数据
- ❌ **手动存储**：已删除复杂的手动存储流程

---

## 📁 文件导入功能

### Excel文件导入

```python
connect_data_source(
    source_type="excel",
    config={
        "file_path": "data/sales.xlsx",
        "sheet_name": "Sheet1"  # 可选，默认第一个工作表
    },
    target_table="sales_data"
)
```

### CSV文件导入

```python
connect_data_source(
    source_type="csv",
    config={
        "file_path": "data/customers.csv",
        "encoding": "utf-8"  # 可选，自动检测
    },
    target_table="customers"
)
```

---

## 🔍 数据查询功能

### 本地数据查询

```python
# 查询本地SQLite数据
execute_sql(
    query="SELECT * FROM sales_data WHERE amount > 1000",
    limit=100
)

# 带参数的安全查询
execute_sql(
    query="SELECT * FROM customers WHERE city = %(city)s",
    params={"city": "北京"},
    limit=50
)
```

### 外部数据库查询

```python
# 查询MySQL数据库
query_external_database(
    database_name="my_mysql",
    query="SELECT COUNT(*) as total FROM users",
    limit=1000
)

# 查询MongoDB
query_external_database(
    database_name="my_mongo",
    query='[{"$match": {"status": "active"}}, {"$count": "total"}]',
    limit=1000
)
```

---

## 📊 数据分析功能

### 基础统计分析

```python
# 基本统计信息
analyze_data(
    analysis_type="basic_stats",
    table_name="sales_data"
)

# 相关性分析
analyze_data(
    analysis_type="correlation",
    table_name="sales_data",
    columns=["amount", "quantity", "price"]
)

# 异常值检测
analyze_data(
    analysis_type="outliers",
    table_name="sales_data",
    columns=["amount"]
)
```

### 数据质量检查

```python
# 缺失值分析
analyze_data(
    analysis_type="missing_values",
    table_name="customers"
)

# 重复值检测
analyze_data(
    analysis_type="duplicates",
    table_name="customers"
)
```

---

## 🛠️ 数据处理功能

### 数据清洗

```python
# 去重和填充缺失值
process_data(
    operation_type="clean",
    data_source="customers",
    config={
        "remove_duplicates": True,
        "fill_missing": {
            "age": {"method": "mean"},
            "city": {"method": "mode"}
        }
    },
    target_table="customers_clean"
)
```

### 数据筛选

```python
# 条件筛选
process_data(
    operation_type="filter",
    data_source="sales_data",
    config={
        "filter_condition": "amount > 1000 AND status = 'completed'",
        "select_columns": ["id", "amount", "date"]
    },
    target_table="high_value_sales"
)
```

### 数据聚合

```python
# 分组统计
process_data(
    operation_type="aggregate",
    data_source="sales_data",
    config={
        "group_by": {
            "columns": ["category", "region"],
            "agg": {
                "amount": ["sum", "mean"],
                "quantity": "count"
            }
        }
    },
    target_table="sales_summary"
)
```

---

## 📤 数据导出功能

### 导出到Excel

```python
# 导出表数据
export_data(
    export_type="excel",
    data_source="sales_summary",
    file_path="exports/sales_report.xlsx"
)

# 导出查询结果
export_data(
    export_type="excel",
    data_source="SELECT * FROM customers WHERE city = '北京'"
)
```

### 导出到CSV

```python
export_data(
    export_type="csv",
    data_source="customers_clean",
    options={
        "encoding": "utf-8-sig",  # 支持中文Excel打开
        "index": False
    }
)
```

---

## 📋 数据信息查询

### 查看数据库结构

```python
# 列出所有表
get_data_info(info_type="tables")

# 查看表结构
get_data_info(
    info_type="schema",
    table_name="sales_data"
)

# 查看统计信息
get_data_info(
    info_type="stats",
    table_name="sales_data"
)
```

### 查看数据源

```python
# 列出所有数据源
list_data_sources()
```

---

## 🎯 最佳实践

### 1. 数据导入流程

```python
# 1. 导入数据
connect_data_source(
    source_type="excel",
    config={"file_path": "data.xlsx"},
    target_table="raw_data"
)

# 2. 检查数据结构
get_data_info(info_type="schema", table_name="raw_data")

# 3. 数据质量检查
analyze_data(analysis_type="missing_values", table_name="raw_data")
analyze_data(analysis_type="duplicates", table_name="raw_data")

# 4. 数据清洗
process_data(
    operation_type="clean",
    data_source="raw_data",
    config={"remove_duplicates": True},
    target_table="clean_data"
)

# 5. 数据分析
analyze_data(analysis_type="basic_stats", table_name="clean_data")

# 6. 导出结果
export_data(export_type="excel", data_source="clean_data")
```

### 2. 数据库连接最佳实践

- 使用配置文件管理数据库连接
- 将敏感信息（密码）存储在环境变量中
- 定期测试数据库连接状态
- 使用临时配置进行快速测试

### 3. API数据获取最佳实践

- 先预览API数据结构
- 使用数据转换配置标准化字段
- 对重要数据启用持久化存储
- 合理设置请求频率和超时时间

---

## ⚠️ 注意事项

### 安全性

- 不要在代码中硬编码密码和API密钥
- 使用环境变量管理敏感信息
- 定期更新数据库密码和API密钥

### 性能优化

- 大数据量查询时使用 `limit` 参数
- 合理使用索引提高查询性能
- 定期清理临时配置和缓存数据

### 错误处理

- 仔细阅读工具返回的错误信息
- 检查数据库连接状态
- 验证SQL语法和参数格式

---

## 🆘 常见问题解决

### 数据库连接问题

**问题**: 连接失败，提示"缺少必需的配置字段"
**解决**: 检查用户名参数，支持 `user` 或 `username`

**问题**: 临时配置不存在
**解决**: 使用 `list_data_sources()` 查看可用配置

### API连接问题

**问题**: API认证失败
**解决**: 检查API密钥和认证配置

**问题**: 数据格式解析错误
**解决**: 使用 `api_data_preview` 先查看数据结构

### 数据处理问题

**问题**: SQL语法错误
**解决**: 使用参数化查询避免语法问题

**问题**: 内存不足
**解决**: 使用 `limit` 参数限制结果集大小

---

## 📞 技术支持

如有问题或建议，请：

1. 查看本手册相关章节
2. 检查工具返回的错误信息
3. 提交Issue或联系开发团队

---

**版本**: v1.0.0  
**更新日期**: 2025年1月24日  
**文档状态**: ✅ 完整版